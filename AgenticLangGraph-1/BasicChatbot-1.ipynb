{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e13e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f815ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "508bb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "     # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d733035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x23e07fcbd40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08a1277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5188780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0e03b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023E08AB7C20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023E09263FE0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = init_chat_model(\"groq:llama3-8b-8192\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db408a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node Functionality\n",
    "def chatbot(state:State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b72e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "# adding node\n",
    "graph_builder.add_node(\"llmchatbot\", chatbot)\n",
    "#adding edge\n",
    "graph_builder.add_edge(START, \"llmchatbot\")\n",
    "graph_builder.add_edge(\"llmchatbot\", END)\n",
    "\n",
    "#Compile the Graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce9912e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7a923ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Expected dict, got Hi\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2843\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2840\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2841\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2843\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2844\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2533\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2531\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2532\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2533\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2534\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2537\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2538\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2539\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2543\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\write.py:86\u001b[39m, in \u001b[36mChannelWrite._write\u001b[39m\u001b[34m(self, input, config)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     78\u001b[39m     writes = [\n\u001b[32m     79\u001b[39m         ChannelWriteEntry(write.channel, \u001b[38;5;28minput\u001b[39m, write.skip_none, write.mapper)\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write.value \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[32m   (...)\u001b[39m\u001b[32m     84\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.writes\n\u001b[32m     85\u001b[39m     ]\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\write.py:128\u001b[39m, in \u001b[36mChannelWrite.do_write\u001b[39m\u001b[34m(config, writes, allow_passthrough)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# if we want to persist writes found before hitting a ParentCommand\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# can move this to a finally block\u001b[39;00m\n\u001b[32m    127\u001b[39m write: TYPE_SEND = config[CONF][CONFIG_KEY_SEND]\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m write(\u001b[43m_assemble_writes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\pregel\\write.py:183\u001b[39m, in \u001b[36m_assemble_writes\u001b[39m\u001b[34m(writes)\u001b[39m\n\u001b[32m    181\u001b[39m     tuples.append((TASKS, w))\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteTupleEntry):\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ww := \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    184\u001b[39m         tuples.extend(ww)\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(w, ChannelWriteEntry):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:975\u001b[39m, in \u001b[36mCompiledStateGraph.attach_node.<locals>._get_updates\u001b[39m\u001b[34m(input)\u001b[39m\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    971\u001b[39m     msg = create_error_message(\n\u001b[32m    972\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected dict, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    973\u001b[39m         error_code=ErrorCode.INVALID_GRAPH_NODE_RETURN_VALUE,\n\u001b[32m    974\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: Expected dict, got Hi\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_GRAPH_NODE_RETURN_VALUE",
      "During task with name '__start__' and id 'dced42d1-bc91-8396-e858-0911bb8e7e7a'"
     ]
    }
   ],
   "source": [
    "graph.invoke(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd5bdb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke({\"messages\":\"Hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "955fc814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}, id='8ed6867e-b9cf-4814-b155-a2de4554af4b'),\n",
       " AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 11, 'total_tokens': 37, 'completion_time': 0.025317621, 'prompt_time': 0.002079913, 'queue_time': 0.19355011, 'total_time': 0.027397534}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_24ec19897b', 'finish_reason': 'stop', 'logprobs': None}, id='run--bb57214e-b6fd-492f-8517-6f7f05679669-0', usage_metadata={'input_tokens': 11, 'output_tokens': 26, 'total_tokens': 37})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfa3750e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 11, 'total_tokens': 37, 'completion_time': 0.025317621, 'prompt_time': 0.002079913, 'queue_time': 0.19355011, 'total_time': 0.027397534}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_24ec19897b', 'finish_reason': 'stop', 'logprobs': None}, id='run--bb57214e-b6fd-492f-8517-6f7f05679669-0', usage_metadata={'input_tokens': 11, 'output_tokens': 26, 'total_tokens': 37})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7e1787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6f9d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'llmchatbot': {'messages': [AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 11, 'total_tokens': 36, 'completion_time': 0.02429205, 'prompt_time': 0.002098724, 'queue_time': 0.194328772, 'total_time': 0.026390774}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_24ec19897b', 'finish_reason': 'stop', 'logprobs': None}, id='run--9401d572-4083-4650-bbb8-d530fc1a2fe0-0', usage_metadata={'input_tokens': 11, 'output_tokens': 25, 'total_tokens': 36})]}}\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi\"}):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24c4a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content=\"Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 11, 'total_tokens': 36, 'completion_time': 0.024167033, 'prompt_time': 0.002618905, 'queue_time': 0.203269448, 'total_time': 0.026785938}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_24ec19897b', 'finish_reason': 'stop', 'logprobs': None}, id='run--586e5b8c-0594-4e0f-b219-acd8570b5fee-0', usage_metadata={'input_tokens': 11, 'output_tokens': 25, 'total_tokens': 36})]}\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi\"}):\n",
    "    for value in event.values():\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "130415f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream({\"messages\":\"Hi\"}):\n",
    "    for value in event.values():\n",
    "        print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684383f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "932909af",
   "metadata": {},
   "source": [
    "CHATBOT WITH TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d299ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:76: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  description=\"\"\"Regex patterns to select only URLs from specific domains or subdomains.\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:95: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  description=\"\"\"Regex patterns to exclude URLs from specific domains or subdomains.\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:233: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"Regex patterns to select only URLs from specific domains or subdomains.\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_crawl.py:243: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:76: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  description=\"\"\"Regex patterns to select only URLs from specific domains or subdomains.\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:95: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  description=\"\"\"Regex patterns to exclude URLs from specific domains or subdomains.\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:217: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"Regex patterns to select only URLs from specific domains or subdomains.\n",
      "d:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_map.py:227: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'what is langgraph',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "   'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "   'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.',\n",
       "   'score': 0.9446333,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "   'title': 'What is LangGraph? - IBM',\n",
       "   'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. LangGraph illuminates the processes within an AI workflow, allowing full transparency of the agent’s state. By combining these technologies with a set of APIs and tools, LangGraph provides users with a versatile platform for developing AI solutions and workflows including chatbots, state graphs and other agent-based systems. Nodes: In LangGraph, nodes represent individual components or agents within an AI workflow. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback.',\n",
       "   'score': 0.9385817,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.72}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tool.invoke(\"what is langgraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a8e6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##custom function\n",
    "def multiply(a:int, b:int) -> int:\n",
    "    \"\"\"multiplt a and b\n",
    "    Args:\n",
    "    a (int): first int\n",
    "    b (int): second int\n",
    "\n",
    "    Returns:\n",
    "    int: output int\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c60bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "984c459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tool = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e1a530c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023E08AB7C20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023E09263FE0>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'tavily_search', 'description': 'A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. It not only retrieves URLs and snippets, but offers advanced search depths, domain management, time range filters, and image search, this tool delivers real-time, accurate, and citation-backed results.Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'Search query to look up', 'type': 'string'}, 'include_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to restrict search results to.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests information from specific websites (e.g., \"Find climate data from nasa.gov\")\\n        2. The user mentions an organization or company without specifying the domain (e.g., \"Find information about iPhones from Apple\")\\n\\n        In both cases, you should determine the appropriate domains (e.g., [\"nasa.gov\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will ONLY come from the specified domains - no other sources will be included.\\n        Default is None (no domain restriction).\\n        '}, 'exclude_domains': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': [], 'description': 'A list of domains to exclude from search results.\\n\\n        Use this parameter when:\\n        1. The user explicitly requests to avoid certain websites (e.g., \"Find information about climate change but not from twitter.com\")\\n        2. The user mentions not wanting results from specific organizations without naming the domain (e.g., \"Find phone reviews but nothing from Apple\")\\n\\n        In both cases, you should determine the appropriate domains to exclude (e.g., [\"twitter.com\"] or [\"apple.com\"]) and set this parameter.\\n\\n        Results will filter out all content from the specified domains.\\n        Default is None (no domain exclusion).\\n        '}, 'search_depth': {'anyOf': [{'enum': ['basic', 'advanced'], 'type': 'string'}, {'type': 'null'}], 'default': 'basic', 'description': 'Controls search thoroughness and result comprehensiveness.\\n    \\n        Use \"basic\" for simple queries requiring quick, straightforward answers.\\n        \\n        Use \"advanced\" (default) for complex queries, specialized topics, \\n        rare information, or when in-depth analysis is needed.\\n        '}, 'include_images': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Determines if the search returns relevant images along with text results.\\n   \\n        Set to True when the user explicitly requests visuals or when images would \\n        significantly enhance understanding (e.g., \"Show me what black holes look like,\" \\n        \"Find pictures of Renaissance art\").\\n        \\n        Leave as False (default) for most informational queries where text is sufficient.\\n        '}, 'time_range': {'anyOf': [{'enum': ['day', 'week', 'month', 'year'], 'type': 'string'}, {'type': 'null'}], 'default': None, 'description': 'Limits results to content published within a specific timeframe.\\n        \\n        ONLY set this when the user explicitly mentions a time period \\n        (e.g., \"latest AI news,\" \"articles from last week\").\\n        \\n        For less popular or niche topics, use broader time ranges \\n        (\"month\" or \"year\") to ensure sufficient relevant results.\\n   \\n        Options: \"day\" (24h), \"week\" (7d), \"month\" (30d), \"year\" (365d).\\n        \\n        Default is None.\\n        '}, 'topic': {'anyOf': [{'enum': ['general', 'news', 'finance'], 'type': 'string'}, {'type': 'null'}], 'default': 'general', 'description': 'Specifies search category for optimized results.\\n   \\n        Use \"general\" (default) for most queries, INCLUDING those with terms like \\n        \"latest,\" \"newest,\" or \"recent\" when referring to general information.\\n\\n        Use \"finance\" for markets, investments, economic data, or financial news.\\n\\n        Use \"news\" ONLY for politics, sports, or major current events covered by \\n        mainstream media - NOT simply because a query asks for \"new\" information.\\n        '}, 'include_favicon': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': False, 'description': 'Whether to include the favicon URL for each result.'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': 'multiplt a and b\\nArgs:\\na (int): first int\\nb (int): second int', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d9015",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'tool_calling_llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m builder.add_edge(\u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m, END)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m#Compile the Graph\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m graph = \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m display(Image(graph.get_graph().draw_mermaid_png()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:822\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    819\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    821\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    831\u001b[39m output_channels = (\n\u001b[32m    832\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output_schema]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    839\u001b[39m     ]\n\u001b[32m    840\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Jeevan\\Agentic_AI_Basics\\AgenticLangGraph-1\\.venv\\Lib\\site-packages\\langgraph\\graph\\state.py:749\u001b[39m, in \u001b[36mStateGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    753\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    754\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'tool_calling_llm'"
     ]
    }
   ],
   "source": [
    "##stateGraph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "##Node Definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tool.invoke(state[\"messages\"])]}\n",
    "\n",
    "##Graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(START, \"tool calling llm\")\n",
    "builder.add_node(\"tool calling llm\",tool_calling_llm)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "## Add Edges\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\", \n",
    "    #If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    #If the latest message (result) from assistant is not a tool call -> tools_condition routes to END\n",
    "    tools_condition \n",
    "    )\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "#Compile the Graph\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83f98ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticlanggraph-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
